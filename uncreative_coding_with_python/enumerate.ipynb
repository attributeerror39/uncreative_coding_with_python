{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate\n",
    "\n",
    "Another way to iterate (loop) over a list is `enumerate()`. With enumerate we'll get an `index` for each item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "world\n",
      "!\n",
      "0 : hello\n",
      "1 : world\n",
      "2 : !\n"
     ]
    }
   ],
   "source": [
    "words = ['hello', 'world', '!']\n",
    "\n",
    "# for-loop\n",
    "for word in words:\n",
    "    print(word)\n",
    "\n",
    "# for-loop with enumerate\n",
    "for index, word in enumerate(words):\n",
    "    print(f\"{index} : {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[\"Hello, world, with your shades of green and blue, You're here to stay, the morning dew\", \" The vast expanse, the creatures, trees, Each tiny grain of sand at the sea's breeze\", ' A symphony of life, a dance so free, Hello, world, in you we breathe', '']\n"
     ]
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "pdf = FPDF(format=(115, 180))\n",
    "pdf.set_font('Helvetica')\n",
    "\n",
    "# Store a longer text in the variable 'text'. \n",
    "text = \"Hello, world, with your shades of green and blue, You're here to stay, the morning dew. The vast expanse, the creatures, trees, Each tiny grain of sand at the sea's breeze. A symphony of life, a dance so free, Hello, world, in you we breathe.\"\n",
    "\n",
    "# Print the data type \n",
    "print(type(text))\n",
    "\n",
    "# Split the text into a list of sentences. \n",
    "sentences = text.split('.')\n",
    "\n",
    "# Print the data type \n",
    "print(type(sentences))\n",
    "\n",
    "# Print the sentences\n",
    "print(sentences)\n",
    "\n",
    "for index, sentence in enumerate(sentences):\n",
    "\n",
    "    pdf.add_page()\n",
    "    pdf.set_font_size(36)\n",
    "    pdf.multi_cell(w=0, text=sentence, align='L')\n",
    "    pdf.set_y(-24)\n",
    "    pdf.set_font_size(10)\n",
    "    pdf.cell(w=0, text=str(index+1), align='R')\n",
    "    \n",
    "pdf.output(\"pdfs/haiku_enumerate.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ![enumerate pdf](img/fpdf_enumerate_1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(string, chunk_size):\n",
    "    chunks = []\n",
    "    for i in range(0, len(string), chunk_size):\n",
    "        chunks.append(string[i:i+chunk_size])\n",
    "    return chunks\n",
    "\n",
    "# Example usage\n",
    "input_string = \"This is an example string to be split into chunks of size 10\"\n",
    "chunk_size = 10\n",
    "chunks = split_into_chunks(input_string, chunk_size)\n",
    "for chunk in chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access list elements with their index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "ðŸ•ðŸ•ðŸ•ðŸ•ðŸ•ðŸ•ðŸ•ðŸ•ðŸ•\n"
     ]
    }
   ],
   "source": [
    "l = [5, \"hello\", -1.5, \"ðŸ\", \"ðŸ•\"*9]\n",
    "\n",
    "print(l[1])\n",
    "print(l[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "ðŸ•ðŸ•ðŸ•ðŸ•ðŸ•ðŸ•ðŸ•ðŸ•ðŸ•\n"
     ]
    }
   ],
   "source": [
    "print(l[0])\n",
    "print(l[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "pdf = FPDF(format=(115, 180))\n",
    "pdf.set_font('Helvetica')\n",
    "\n",
    "\n",
    "with open('data/wordlist.txt', 'r') as f:\n",
    "    wordlist = f.readlines()\n",
    "\n",
    "with open('data/for_loop_haiku.txt', 'r') as f:  \n",
    "    haiku = f.read()\n",
    "\n",
    "# Split the haiku into a list\n",
    "haiku_lines = haiku.split('\\n')\n",
    "\n",
    "# Iterate over the lines\n",
    "for index, line in enumerate(haiku_lines):\n",
    "\n",
    "    # Look up the page number through the index\n",
    "    page_number = wordlist[index]\n",
    "\n",
    "    pdf.add_page()\n",
    "    pdf.set_font_size(36)\n",
    "    pdf.multi_cell(w=0, text=line, align='L')\n",
    "    pdf.set_y(-24)\n",
    "    pdf.set_font_size(10)\n",
    "    pdf.cell(w=0, text=page_number, align='R')\n",
    "\n",
    "pdf.output(\"pdfs/haiku_enumerate_wordlist.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ![haiku enumerate wordlist](img/haiku_enumerate_wordlist.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "up",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
