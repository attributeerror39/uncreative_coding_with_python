{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68eda55c",
   "metadata": {},
   "source": [
    "# Images\n",
    "\n",
    "## Introduction to Digital Images\n",
    "\n",
    "Digital images are stored as a grid (matrix) of colored dots called **pixels**. Each pixel typically has three primary color values:\n",
    "\n",
    "- **Red**\n",
    "- **Green**\n",
    "- **Blue**\n",
    "\n",
    "Hence, in code, an RGB image can be considered a 3D array (list) with dimensions corresponding to `(height, width, channels)`. For instance, a 640×480 image has 640 pixels in width (horizontal) and 480 in height (vertical), each pixel containing an `(R, G, B)` triplet.\n",
    "\n",
    "Sometimes, there's an **Alpha** channel (RGBA) representing transparency. We’ll focus on standard RGB for simplicity.\n",
    "\n",
    "In Python, the **Pillow** library (PIL) is a common tool for reading and writing these images, while libraries like [**diffusers**](https://github.com/huggingface/diffusers) offer utility functions (like `load_image`) for convenience.\n",
    "\n",
    "We’ll explore both **Pillow**, **numpy** and **diffusers** for:\n",
    "\n",
    "1. Loading images\n",
    "2. Manipulating images\n",
    "3. Creating simple animations (MP4s)\n",
    "\n",
    "Let’s start by installing and importing the necessary libraries.\n",
    "\n",
    "We will install all necessary libraries in one step using **pip** like discussed in previous chapters:\n",
    "\n",
    "`pip install pillow numpy diffusers tqdm`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2a84c",
   "metadata": {},
   "source": [
    "## Loading Images\n",
    "\n",
    "There are multiple ways in different libraries to load images stored locally on our device. The most common way is to load it using Pillow (a fort of PIL). See [readthedocs.io](https://pillow.readthedocs.io/en/stable/handbook/tutorial.html) and [automate the boring stuff](https://automatetheboringstuff.com/chapter17/) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44079481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # Import the Image class\n",
    "\n",
    "img = Image.open(\"sample.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c079cbe",
   "metadata": {},
   "source": [
    "We can inspect the loaded image like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc24b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: (512, 512)\n",
      "mode: RGB\n",
      "format: JPEG\n"
     ]
    }
   ],
   "source": [
    "print('size:', img.size)\n",
    "print('mode:', img.mode)\n",
    "print('format:', img.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01724bf",
   "metadata": {},
   "source": [
    "To display an image, we can use the show method, which will open the image in the default image-viewer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2af579",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d979907",
   "metadata": {},
   "source": [
    "### Loading from the Web\n",
    "\n",
    "`Image.open` will only work with local files and return a `PIL`. The `diffusers` library provides a helper function to load images from the web (via ursl) or from disk (using paths)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d44712b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image\n",
    "\n",
    "img = load_image(\"https://thispersondoesnotexist.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8990bd",
   "metadata": {},
   "source": [
    "The resulting image will be in the `PIL` format aswell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc24080c",
   "metadata": {},
   "source": [
    "### Saving images\n",
    "\n",
    "Images loaded in the `PIL` format can be saved locally with a call to `save` which takes a path as the parameter. If no format is provided it will be chosen according to the file-extension in the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a16f0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image\n",
    "\n",
    "img = load_image(\"https://thispersondoesnotexist.com/\")\n",
    "\n",
    "img.save(\"face1.png\", format=\"PNG\") # Explicit PNG\n",
    "\n",
    "img.save(\"face2.png\") # Implicit PNG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f307cc8",
   "metadata": {},
   "source": [
    "## Manipulating Images\n",
    "\n",
    "Pillow provides many methods for image manipulation. Here are some common ones:\n",
    "\n",
    "1. **Rotate**: `image.rotate(angle, expand=True)`.\n",
    "2. **Resize (Scale)**: `image.resize((new_width, new_height))`.\n",
    "3. **Blur**: using `ImageFilter.BLUR` or other filters from `ImageFilter`.\n",
    "4. **Enhance Contrast**: using `ImageEnhance.Contrast(image)`.\n",
    "5. **Composite**: combine multiple images using `Image.composite`.\n",
    "\n",
    "We'll demonstrate these on an example image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e87d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image\n",
    "\n",
    "img = load_image(\"https://thispersondoesnotexist.com/\")\n",
    "\n",
    "# 1. Rotate\n",
    "rotated_image = img.rotate(45, expand=True)\n",
    "rotated_image.save(\"img/rotated.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de091d",
   "metadata": {},
   "source": [
    "![rotated](img/rotated.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e0c8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Scale\n",
    "width, height = img.size\n",
    "half_sized_image = img.resize((width // 2, height // 2))\n",
    "half_sized_image = img.save(\"img/scaled.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf9470",
   "metadata": {},
   "source": [
    "![rotated](img/scaled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4410332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Blur\n",
    "from PIL import ImageFilter\n",
    "blurred_image = img.filter(ImageFilter.BLUR)\n",
    "blurred_image.save(\"img/blurred.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a382ff7",
   "metadata": {},
   "source": [
    "![rotated](img/blurred.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f66d1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Enhance Contrast\n",
    "from PIL import ImageEnhance\n",
    "enhancer = ImageEnhance.Contrast(img)\n",
    "contrast_image = enhancer.enhance(2.0)  # Increase contrast\n",
    "contrast_image.save(\"img/enhanced.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85507790",
   "metadata": {},
   "source": [
    "![rotated](img/enhanced.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f5164a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Composite\n",
    "# For demonstration, we composite the original and blurred image using a gradient mask.\n",
    "mask = Image.linear_gradient(\"L\").resize(img.size)\n",
    "img_rgba = img.convert(\"RGBA\")\n",
    "blurred_rgba = blurred_image.convert(\"RGBA\")\n",
    "composited_img = Image.composite(img_rgba, blurred_rgba, mask)\n",
    "composited_img.save(\"img/composited.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c300b5e",
   "metadata": {},
   "source": [
    "![composited](img/composited.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b86ddb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Crop\n",
    "cropped = img.crop((0, 0, 256, 50))\n",
    "cropped.save(\"img/cropped.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21c76a",
   "metadata": {},
   "source": [
    "![cropped](img/cropped.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b4749",
   "metadata": {},
   "source": [
    "### Creatin a simple animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "126e62de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 49.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rotating.gif'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers.utils import load_image, export_to_gif\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the image\n",
    "img = load_image(\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fimages.carexpert.com.au%2Fresize%2F3000%2F-%2Fapp%2Fuploads%2F2023%2F04%2Fmini-hatch-1.jpg&f=1&nofb=1&ipt=c704c396057008b8b907cfb55732154ea8f02aebac29d5765389202c61b0e9ce\")\n",
    "\n",
    "# Create empty list of frames\n",
    "frames = []\n",
    "\n",
    "# Manipulate the image\n",
    "for i in tqdm(range(10)):\n",
    "    \n",
    "    # Manipulate the image here:\n",
    "    img = img.rotate(4)\n",
    "\n",
    "    # Add the image to the frames list\n",
    "    frames.append(img)\n",
    "    \n",
    "# Save frames as animation\n",
    "export_to_gif(frames, \"rotating.gif\", fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790de91",
   "metadata": {},
   "source": [
    "![System](rotating.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2c030f",
   "metadata": {},
   "source": [
    "## Building a Simple Dynamical System with Image Filters\n",
    "\n",
    "A **dynamical system** evolves over time by repeatedly applying the same (or similar) rules. Here, we’ll apply filters (blur, sharpen, rotate, etc.) in a loop, treating each new image as the input for the next iteration.\n",
    "\n",
    "**Learn more**: [Reaction–diffusion systems](https://en.wikipedia.org/wiki/Reaction–diffusion_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fed217ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:02<00:00, 28.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'system.gif'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers.utils import export_to_gif\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 2. Load a base image\n",
    "img = load_image(\"https://thispersondoesnotexist.com/\").convert(\"RGB\")\n",
    "\n",
    "# 3. Iteratively apply transformations\n",
    "num_frames = 60\n",
    "frames = []\n",
    "\n",
    "for i in tqdm(range(num_frames)):\n",
    "    img = img.filter(ImageFilter.BLUR)\n",
    "    img = img.filter(ImageFilter.SHARPEN)\n",
    "    frames.append(img)\n",
    "    \n",
    "export_to_gif(frames, \"system.gif\", fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c784c2dc",
   "metadata": {},
   "source": [
    "![System](system.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe9330bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:02<00:00, 25.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'system2.gif'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers.utils import export_to_gif\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 2. Load a base image\n",
    "img = load_image(\"https://thispersondoesnotexist.com/\").convert(\"RGB\")\n",
    "\n",
    "# 3. Iteratively apply transformations\n",
    "num_frames = 60\n",
    "frames = []\n",
    "\n",
    "for i in tqdm(range(num_frames)):\n",
    "    img = img.filter(ImageFilter.GaussianBlur(radius=4))\n",
    " \n",
    "    # use a fixed sharpen amount (or vary it too)\n",
    "    img = img.filter(ImageFilter.UnsharpMask(radius=10, percent=550, threshold=1))\n",
    "    frames.append(img)\n",
    "    \n",
    "export_to_gif(frames, \"system2.gif\", fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42276501",
   "metadata": {},
   "source": [
    "![System](system2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b10f6c8",
   "metadata": {},
   "source": [
    "### Example: Repeated Blur + Sharpen + Rotation\n",
    "We’ll do the following:\n",
    "1. Load an initial image.\n",
    "2. Rotate it slightly, then blur and sharpen.\n",
    "3. Save each iteration.\n",
    "4. Export all frames as an GIF using `export_to_gif`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ad06700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating frames: 100%|██████████| 60/60 [00:04<00:00, 13.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from diffusers.utils import export_to_gif\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Define the transformation steps\n",
    "def blur_then_sharpen(input_image: Image.Image) -> Image.Image:\n",
    "    blurred = input_image.filter(ImageFilter.BLUR)\n",
    "    sharpened = blurred.filter(ImageFilter.SHARPEN)\n",
    "    return sharpened\n",
    "\n",
    "# 2. Load a base image\n",
    "original_img = load_image(\"https://thispersondoesnotexist.com/\").convert(\"RGB\")\n",
    "\n",
    "\n",
    "# 3. Iteratively apply transformations\n",
    "num_frames = 60\n",
    "frames = []\n",
    "\n",
    "current_img = original_img\n",
    "angle = 0\n",
    "\n",
    "for i in tqdm(range(num_frames), desc=\"Generating frames\"):\n",
    "    # Rotate slightly\n",
    "    rotated = current_img.rotate(angle, expand=True)\n",
    "\n",
    "    # Blur + Sharpen\n",
    "    processed = rotated.filter(ImageFilter.BLUR).filter(ImageFilter.SHARPEN)\n",
    "\n",
    "    # Resize back to original shape if rotation changed dimensions\n",
    "    processed = processed.resize(original_img.size)\n",
    "\n",
    "    # Accumulate frames\n",
    "    frames.append(processed)\n",
    "\n",
    "    # Prepare next iteration\n",
    "    current_img = processed\n",
    "    angle += 1  # 1 degree each iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c19b9b",
   "metadata": {},
   "source": [
    "### Exporting the Frames as an MP4\n",
    "We can now call `export_to_video` to compile these frames into a video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcc870cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'animation.gif'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_to_gif(\n",
    "    frames,\n",
    "    output_gif_path=\"animation.gif\",\n",
    "    fps=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8548c9",
   "metadata": {},
   "source": [
    "![Animation](animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955177e6",
   "metadata": {},
   "source": [
    "### Loading Images as numpy\n",
    "\n",
    "We can also use numpy to read an image direclty as a three-dimensional list of color values. for that we can convert any `PIL` image to `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d98ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions: 3\n",
      "shape: (1024, 1024, 3)\n",
      "size 3145728\n"
     ]
    }
   ],
   "source": [
    "from diffusers.utils import load_image\n",
    "import numpy as np # numpy is usually renamed to np\n",
    "\n",
    "# Load as PIL\n",
    "img_pil = load_image(\"https://thispersondoesnotexist.com/\")\n",
    "\n",
    "\n",
    "# convert to numpy\n",
    "img_np = np.asarray(img_pil)\n",
    "print('dimensions:', img_np.ndim)\n",
    "print('shape:', img_np.shape)\n",
    "print('size', img_np.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6712023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[166 161 142]\n",
      "  [167 160 141]\n",
      "  [160 154 130]\n",
      "  ...\n",
      "  [157 151 127]\n",
      "  [157 149 128]\n",
      "  [151 143 124]]\n",
      "\n",
      " [[167 162 143]\n",
      "  [163 156 137]\n",
      "  [161 154 135]\n",
      "  ...\n",
      "  [156 150 126]\n",
      "  [159 153 131]\n",
      "  [159 153 131]]\n",
      "\n",
      " [[164 159 140]\n",
      "  [163 156 138]\n",
      "  [162 155 137]\n",
      "  ...\n",
      "  [158 154 129]\n",
      "  [162 157 135]\n",
      "  [157 155 132]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 25  25  23]\n",
      "  [ 21  21  19]\n",
      "  [ 24  23  21]\n",
      "  ...\n",
      "  [ 24  25  20]\n",
      "  [ 22  23  18]\n",
      "  [ 22  23  17]]\n",
      "\n",
      " [[ 30  30  30]\n",
      "  [ 22  20  21]\n",
      "  [ 19  18  16]\n",
      "  ...\n",
      "  [ 20  22  21]\n",
      "  [ 19  21  18]\n",
      "  [ 25  25  23]]\n",
      "\n",
      " [[ 39  37  40]\n",
      "  [ 22  20  23]\n",
      "  [ 22  20  21]\n",
      "  ...\n",
      "  [ 20  24  25]\n",
      "  [ 24  28  29]\n",
      "  [ 38  40  39]]]\n"
     ]
    }
   ],
   "source": [
    "print(img_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2c480c",
   "metadata": {},
   "source": [
    "We can now manipulate pixel values directly using mathematical functions, but we can also use generative artificial intelligence to write the functions for us. For that we will just need to formulate our prompt accordingly.\n",
    "\n",
    "As a base prompt we can use the following:\n",
    "\n",
    "`Give me a python function that takes an image in numpy format (RGB) and manipulates it. The function should return a numpy array in the same format and be called my_function. The function should ...`\n",
    "\n",
    "Using this prompt and descriptions for what should happen with the image we can manipulate without writing the code ourselves.\n",
    "\n",
    "For example:\n",
    "\n",
    "`The function should make the image grayscale.`\n",
    "\n",
    "`The function should invert the image.`\n",
    "\n",
    "`The function should sort pixels in the image by brightness.`\n",
    "\n",
    "Paste the resulting funtion into your code and execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807db600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image\n",
    "\n",
    "# Paste your function here:\n",
    "\n",
    "def my_function(img):\n",
    "    return img\n",
    "\n",
    "img_pil = load_image(\"https://thispersondoesnotexist.com/\")\n",
    "img_np = np.asarray(img_pil)\n",
    "\n",
    "manipulated_img = my_function(img_np)\n",
    "\n",
    "Image.fromarray(manipulated_img).save(\"img/manipulated.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
