{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68eda55c",
   "metadata": {},
   "source": [
    "# Images\n",
    "\n",
    "## Introduction to Digital Images\n",
    "\n",
    "Digital images are stored as a grid (matrix) of colored dots called **pixels**. Each pixel typically has three primary color values:\n",
    "\n",
    "- **Red**\n",
    "- **Green**\n",
    "- **Blue**\n",
    "\n",
    "Hence, in code, an RGB image can be considered a 3D array (list) with dimensions corresponding to `(height, width, channels)`. For instance, a 640×480 image has 640 pixels in width (horizontal) and 480 in height (vertical), each pixel containing an `(R, G, B)` triplet.\n",
    "\n",
    "Sometimes, there's an **Alpha** channel (RGBA) representing transparency. We’ll focus on standard RGB for simplicity.\n",
    "\n",
    "In Python, the **Pillow** library (PIL) is a common tool for reading and writing these images, while libraries like [**diffusers**](https://github.com/huggingface/diffusers) offer utility functions (like `load_image`) for convenience.\n",
    "\n",
    "We’ll explore both **Pillow**, **numpy** and **diffusers** for:\n",
    "\n",
    "1. Loading images\n",
    "2. Manipulating images\n",
    "3. Creating simple animations (MP4s)\n",
    "\n",
    "Let’s start by installing and importing the necessary libraries.\n",
    "\n",
    "We will install all necessary libraries in one step using **pip** like discussed in previous chapters:\n",
    "\n",
    "`pip install pillow numpy diffusers tqdm`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2a84c",
   "metadata": {},
   "source": [
    "## Loading Images\n",
    "\n",
    "There are multiple ways in different libraries to load images stored locally on our device. The most common way is to load it using Pillow (a fort of PIL). See [readthedocs.io](https://pillow.readthedocs.io/en/stable/handbook/tutorial.html) and [automate the boring stuff](https://automatetheboringstuff.com/chapter17/) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44079481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # Import the Image class\n",
    "\n",
    "img = Image.open(\"sample.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c079cbe",
   "metadata": {},
   "source": [
    "We can inspect the loaded image like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc24b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: (512, 512)\n",
      "mode: RGB\n",
      "format: JPEG\n"
     ]
    }
   ],
   "source": [
    "print('size:', img.size)\n",
    "print('mode:', img.mode)\n",
    "print('format:', img.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01724bf",
   "metadata": {},
   "source": [
    "To display an image, we can use the show method, which will open the image in the default image-viewer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de2af579",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d979907",
   "metadata": {},
   "source": [
    "### Loading from the Web\n",
    "\n",
    "`Image.open` will only work with local files and return a `PIL`. The `diffusers` library provides a helper function to load images from the web (via ursl) or from disk (using paths)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d44712b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image\n",
    "\n",
    "img = load_image(\"https://thispersondoesnotexist.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8990bd",
   "metadata": {},
   "source": [
    "The resulting image will be in the `PIL` format aswell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc24080c",
   "metadata": {},
   "source": [
    "### Saving images\n",
    "\n",
    "Images loaded in the `PIL` format can be saved locally with a call to `save` which takes a path as the parameter. If no format is provided it will be chosen according to the file-extension in the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a16f0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image\n",
    "\n",
    "img = load_image(\"https://thispersondoesnotexist.com/\")\n",
    "\n",
    "img.save(\"face1.png\", format=\"PNG\") # Explicit PNG\n",
    "\n",
    "img.save(\"face2.png\") # Implicit PNG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f307cc8",
   "metadata": {},
   "source": [
    "## Manipulating Images\n",
    "\n",
    "Pillow provides many methods for image manipulation. Here are some common ones:\n",
    "\n",
    "1. **Rotate**: `image.rotate(angle, expand=True)`.\n",
    "2. **Resize (Scale)**: `image.resize((new_width, new_height))`.\n",
    "3. **Blur**: using `ImageFilter.BLUR` or other filters from `ImageFilter`.\n",
    "4. **Enhance Contrast**: using `ImageEnhance.Contrast(image)`.\n",
    "5. **Composite**: combine multiple images using `Image.composite`.\n",
    "\n",
    "We'll demonstrate these on an example image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e87d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image\n",
    "\n",
    "img = load_image(\"https://thispersondoesnotexist.com/\")\n",
    "\n",
    "# 1. Rotate\n",
    "rotated_image = img.rotate(45, expand=True)\n",
    "rotated_image.save(\"img/rotated.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de091d",
   "metadata": {},
   "source": [
    "![rotated](img/rotated.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e0c8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Scale\n",
    "width, height = img.size\n",
    "half_sized_image = img.resize((width // 2, height // 2))\n",
    "half_sized_image = img.save(\"img/scaled.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf9470",
   "metadata": {},
   "source": [
    "![rotated](img/scaled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4410332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Blur\n",
    "from PIL import ImageFilter\n",
    "blurred_image = img.filter(ImageFilter.BLUR)\n",
    "blurred_image.save(\"img/blurred.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a382ff7",
   "metadata": {},
   "source": [
    "![rotated](img/blurred.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f66d1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Enhance Contrast\n",
    "from PIL import ImageEnhance\n",
    "enhancer = ImageEnhance.Contrast(img)\n",
    "contrast_image = enhancer.enhance(2.0)  # Increase contrast\n",
    "contrast_image.save(\"img/enhanced.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85507790",
   "metadata": {},
   "source": [
    "![rotated](img/enhanced.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f5164a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Composite\n",
    "# For demonstration, we composite the original and blurred image using a gradient mask.\n",
    "mask = Image.linear_gradient(\"L\").resize(img.size)\n",
    "img_rgba = img.convert(\"RGBA\")\n",
    "blurred_rgba = blurred_image.convert(\"RGBA\")\n",
    "composited_img = Image.composite(img_rgba, blurred_rgba, mask)\n",
    "composited_img.save(\"img/composited.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c300b5e",
   "metadata": {},
   "source": [
    "![composited](img/composited.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b86ddb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Crop\n",
    "cropped = img.crop((0, 0, 256, 50))\n",
    "cropped.save(\"img/cropped.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21c76a",
   "metadata": {},
   "source": [
    "![cropped](img/cropped.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248bc71e",
   "metadata": {},
   "source": [
    "### Loading Images as numpy\n",
    "\n",
    "We can also use numpy to read an image direclty as a three-dimensional list of color values. for that we can convert any `PIL` image to `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a90a710b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions: 3\n",
      "shape: (1024, 1024, 3)\n",
      "size 3145728\n"
     ]
    }
   ],
   "source": [
    "from diffusers.utils import load_image\n",
    "import numpy as np # numpy is usually renamed to np\n",
    "\n",
    "# Load as PIL\n",
    "img_pil = load_image(\"https://thispersondoesnotexist.com/\")\n",
    "\n",
    "\n",
    "# convert to numpy\n",
    "img_np = np.asarray(img_pil)\n",
    "print('dimensions:', img_np.ndim)\n",
    "print('shape:', img_np.shape)\n",
    "print('size', img_np.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab290296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[162 156 168]\n",
      "  [161 157 171]\n",
      "  [154 153 169]\n",
      "  ...\n",
      "  [162 158 172]\n",
      "  [165 154 170]\n",
      "  [160 145 164]]\n",
      "\n",
      " [[163 159 174]\n",
      "  [157 154 171]\n",
      "  [153 154 172]\n",
      "  ...\n",
      "  [158 158 170]\n",
      "  [164 157 173]\n",
      "  [166 157 174]]\n",
      "\n",
      " [[159 157 178]\n",
      "  [153 154 174]\n",
      "  [154 155 173]\n",
      "  ...\n",
      "  [160 162 174]\n",
      "  [164 163 177]\n",
      "  [164 162 176]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[126 126 154]\n",
      "  [129 131 154]\n",
      "  [128 133 153]\n",
      "  ...\n",
      "  [128 134 156]\n",
      "  [128 134 156]\n",
      "  [130 137 156]]\n",
      "\n",
      " [[130 126 153]\n",
      "  [128 128 152]\n",
      "  [130 135 155]\n",
      "  ...\n",
      "  [128 134 156]\n",
      "  [132 134 155]\n",
      "  [137 138 159]]\n",
      "\n",
      " [[138 132 158]\n",
      "  [127 127 151]\n",
      "  [125 131 153]\n",
      "  ...\n",
      "  [130 137 156]\n",
      "  [142 143 164]\n",
      "  [148 143 166]]]\n"
     ]
    }
   ],
   "source": [
    "print(img_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14238ba4",
   "metadata": {},
   "source": [
    "We can now manipulate pixel values directly using mathematical functions, but we can also use generative artificial intelligence to write the functions for us. For that we will just need to formulate our prompt accordingly.\n",
    "\n",
    "As a base prompt we can use the following:\n",
    "\n",
    "`Give me a python function that takes an image in numpy format (RGB) and manipulates it. The function should return a numpy array in the same format and be called my_function. The function should ...`\n",
    "\n",
    "Using this prompt and descriptions for what should happen with the image we can manipulate without writing the code ourselves.\n",
    "\n",
    "For example:\n",
    "\n",
    "`The function should make the image grayscale.`\n",
    "\n",
    "`The function should invert the image.`\n",
    "\n",
    "`The function should sort pixels in the image by brightness.`\n",
    "\n",
    "Paste the resulting funtion into your code and execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a3f64a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image\n",
    "\n",
    "# Paste your function here:\n",
    "\n",
    "def my_function(img):\n",
    "    return img\n",
    "\n",
    "img_pil = load_image(\"https://thispersondoesnotexist.com/\")\n",
    "img_np = np.asarray(img_pil)\n",
    "\n",
    "manipulated_img = my_function(img_np)\n",
    "\n",
    "Image.fromarray(manipulated_img).save(\"img/manipulated.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2c030f",
   "metadata": {},
   "source": [
    "## Building a Simple Dynamical System with Image Filters\n",
    "\n",
    "A **dynamical system** evolves over time by repeatedly applying the same (or similar) rules. Here, we’ll apply filters (blur, sharpen, rotate, etc.) in a loop, treating each new image as the input for the next iteration.\n",
    "\n",
    "**Learn more**: [Reaction–diffusion systems](https://en.wikipedia.org/wiki/Reaction–diffusion_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed217ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:02<00:00, 28.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'system.gif'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers.utils import export_to_gif\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 2. Load a base image\n",
    "img = load_image(\"https://thispersondoesnotexist.com/\").convert(\"RGB\")\n",
    "\n",
    "# 3. Iteratively apply transformations\n",
    "num_frames = 60\n",
    "frames = []\n",
    "\n",
    "for i in tqdm(range(num_frames)):\n",
    "    img = img.filter(ImageFilter.BLUR)\n",
    "    img = img.filter(ImageFilter.SHARPEN)\n",
    "    frames.append(img)\n",
    "    \n",
    "export_to_gif(frames, \"system.gif\", fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c784c2dc",
   "metadata": {},
   "source": [
    "![System](system.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe9330bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:02<00:00, 21.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'system2.gif'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers.utils import export_to_gif\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 2. Load a base image\n",
    "img = load_image(\"https://thispersondoesnotexist.com/\").convert(\"RGB\")\n",
    "\n",
    "# 3. Iteratively apply transformations\n",
    "num_frames = 60\n",
    "frames = []\n",
    "\n",
    "for i in tqdm(range(num_frames)):\n",
    "    img = img.filter(ImageFilter.GaussianBlur(radius=4))\n",
    " \n",
    "    # use a fixed sharpen amount (or vary it too)\n",
    "    img = img.filter(ImageFilter.UnsharpMask(radius=10, percent=550, threshold=1))\n",
    "    frames.append(img)\n",
    "    \n",
    "export_to_gif(frames, \"system2.gif\", fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42276501",
   "metadata": {},
   "source": [
    "![System](system2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b10f6c8",
   "metadata": {},
   "source": [
    "### Example: Repeated Blur + Sharpen + Rotation\n",
    "We’ll do the following:\n",
    "1. Load an initial image.\n",
    "2. Rotate it slightly, then blur and sharpen.\n",
    "3. Save each iteration.\n",
    "4. Export all frames as an GIF using `export_to_gif`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ad06700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating frames: 100%|██████████| 60/60 [00:04<00:00, 13.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from diffusers.utils import export_to_gif\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Define the transformation steps\n",
    "def blur_then_sharpen(input_image: Image.Image) -> Image.Image:\n",
    "    blurred = input_image.filter(ImageFilter.BLUR)\n",
    "    sharpened = blurred.filter(ImageFilter.SHARPEN)\n",
    "    return sharpened\n",
    "\n",
    "# 2. Load a base image\n",
    "original_img = load_image(\"https://thispersondoesnotexist.com/\").convert(\"RGB\")\n",
    "\n",
    "\n",
    "# 3. Iteratively apply transformations\n",
    "num_frames = 60\n",
    "frames = []\n",
    "\n",
    "current_img = original_img\n",
    "angle = 0\n",
    "\n",
    "for i in tqdm(range(num_frames), desc=\"Generating frames\"):\n",
    "    # Rotate slightly\n",
    "    rotated = current_img.rotate(angle, expand=True)\n",
    "\n",
    "    # Blur + Sharpen\n",
    "    processed = rotated.filter(ImageFilter.BLUR).filter(ImageFilter.SHARPEN)\n",
    "\n",
    "    # Resize back to original shape if rotation changed dimensions\n",
    "    processed = processed.resize(original_img.size)\n",
    "\n",
    "    # Accumulate frames\n",
    "    frames.append(processed)\n",
    "\n",
    "    # Prepare next iteration\n",
    "    current_img = processed\n",
    "    angle += 1  # 1 degree each iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c19b9b",
   "metadata": {},
   "source": [
    "### Exporting the Frames as an MP4\n",
    "We can now call `export_to_video` to compile these frames into a video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcc870cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'animation.gif'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_to_gif(\n",
    "    frames,\n",
    "    output_gif_path=\"animation.gif\",\n",
    "    fps=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8548c9",
   "metadata": {},
   "source": [
    "![Animation](animation.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
